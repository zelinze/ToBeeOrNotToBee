{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 250 images and 250 masks.\n",
      "   ID bug_type         species\n",
      "0   1      Bee  Apis mellifera\n",
      "1   2      Bee  Apis mellifera\n",
      "2   3      Bee  Apis mellifera\n",
      "3   4      Bee  Apis mellifera\n",
      "4   5      Bee  Apis mellifera\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "from PIL import Image \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "img_dir = 'train'\n",
    "mask_dir = 'train/masks'\n",
    "excel_file = 'train/classif.xlsx'\n",
    "\n",
    "# Load images\n",
    "def load_images(img_dir, count):\n",
    "    images = []\n",
    "    for i in range(1, count + 1):\n",
    "        img_path = os.path.join(img_dir, f\"{i}.jpg\")\n",
    "        if os.path.exists(img_path):\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB format\n",
    "            images.append(img)\n",
    "        else:\n",
    "            print(f\"Image {img_path} not found.\")\n",
    "    return images\n",
    "\n",
    "# Load masks\n",
    "def load_masks(mask_dir, count):\n",
    "    masks = []\n",
    "    for i in range(1, count + 1):\n",
    "        mask_path = os.path.join(mask_dir, f\"binary_{i}.tif\")\n",
    "        if os.path.exists(mask_path):\n",
    "            mask = Image.open(mask_path)\n",
    "            mask = np.array(mask)\n",
    "            masks.append(mask)\n",
    "        else:\n",
    "            print(f\"Mask {mask_path} not found.\")\n",
    "    return masks\n",
    "\n",
    "# Load classification file\n",
    "def load_classification(excel_file):\n",
    "    if os.path.exists(excel_file):\n",
    "        return pd.read_excel(excel_file)\n",
    "    else:\n",
    "        print(f\"Excel file {excel_file} not found.\")\n",
    "        return None\n",
    "    \n",
    "# Print        \n",
    "images = load_images(img_dir, 250)\n",
    "masks = load_masks(mask_dir, 250)\n",
    "classif_df = load_classification(excel_file)    \n",
    "\n",
    "print(f\"Loaded {len(images)} images and {len(masks)} masks.\")\n",
    "print(classif_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      SymmetryIndex\n",
      "0         0.804721\n",
      "1         0.772273\n",
      "2         0.593619\n",
      "3         0.487819\n",
      "4         0.666718\n",
      "..             ...\n",
      "245       0.621142\n",
      "246       0.774722\n",
      "247       0.634358\n",
      "248       0.506549\n",
      "249       0.498039\n",
      "\n",
      "[250 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Symmetry index \"\"\"\n",
    "def calculate_symmetry_index(mask):\n",
    "\n",
    "    # Flip the mask horizontally\n",
    "    flipped_mask = np.fliplr(mask)\n",
    "\n",
    "    # Calculate the symmetry as the inverse of the normalized sum of absolute differences\n",
    "    symmetry = 1.0 - (np.sum(np.abs(mask - flipped_mask)) / (2 * np.sum(mask)))\n",
    "    return symmetry\n",
    "\n",
    "# Apply the function to all\n",
    "# IMPORTANT the putout of this function, a list for symmetry_indices and certain value for symmetry_index\n",
    "symmetry_index = calculate_symmetry_index(masks[0])\n",
    "symmetry_indices = [calculate_symmetry_index(mask) for mask in masks]\n",
    "symmetry_df = pd.DataFrame(symmetry_indices, columns=['SymmetryIndex'])\n",
    "print(symmetry_df.head)\n",
    "\n",
    "# Print first 10 symmetry indices\n",
    "#for i, si in enumerate(symmetry_indices[:10]):  # Print first 10 symmetry indices\n",
    "#    print(f\"Symmetry index for mask {i+1}: {si}\")\n",
    "\n",
    "# put the new feature in a csv\n",
    "data_features_df = pd.DataFrame(symmetry_indices, columns=['SymmetryIndex'])\n",
    "# data_features_df.to_csv('data_features.csv', index=False)\n",
    "# print(data_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      LongestOrthogonalRatio\n",
      "0                  0.821019\n",
      "1                  0.675619\n",
      "2                  0.805196\n",
      "3                  0.709335\n",
      "4                  0.744057\n",
      "..                      ...\n",
      "245                0.985775\n",
      "246                0.714783\n",
      "247                0.773522\n",
      "248                0.944525\n",
      "249                0.706377\n",
      "\n",
      "[250 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Ratio of longest orthogonal lines \"\"\"\n",
    "def longest_orthogonal_ratio(mask):\n",
    "    if len(mask.shape) == 3:\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours and len(contours) > 0: # findContours: Find the outline of the bug in the image\n",
    "        rect = cv2.minAreaRect(contours[0]) # minAreaRect: find Minimum Bounding Rectangle\n",
    "        width, height = rect[1] \n",
    "        if width == 0 or height == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(width, height) / max(width, height) # calcule ratio by height/width\n",
    "    return 0\n",
    "\n",
    "# Calculate the ratio for all masks\n",
    "longest_orthogonal_ratios = [longest_orthogonal_ratio(mask) for mask in masks]\n",
    "longest_orthogonal_ratio_df = pd.DataFrame(longest_orthogonal_ratios, columns=['LongestOrthogonalRatio'])\n",
    "print(longest_orthogonal_ratio_df.head)\n",
    "\n",
    "# Print first 10 ratios\n",
    "#for i, ratio in enumerate(longest_orthogonal_ratios[:10]):\n",
    "#    print(f\"Longest orthogonal ratio for mask {i+1}: {ratio}\")\n",
    "\n",
    "# Merge the new feature \n",
    "data_features_df = pd.concat([data_features_df,longest_orthogonal_ratio_df], axis=1)\n",
    "#data_features_df.to_csv('data_features.csv', index=False)\n",
    "#print(data_features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of         ratio\n",
      "0    0.022284\n",
      "1    0.025659\n",
      "2    0.066279\n",
      "3    0.039562\n",
      "4    0.027494\n",
      "..        ...\n",
      "245  0.006250\n",
      "246  0.020050\n",
      "247  0.007032\n",
      "248  0.011959\n",
      "249  0.023367\n",
      "\n",
      "[250 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Ratio of bug pixels to total pixels \"\"\"\n",
    "def bug_to_total_ratio(mask):\n",
    "    bug_pixels = np.sum(mask > 0)  # Count the number of pixels for bugs\n",
    "    total_pixels = mask.shape[0] * mask.shape[1]  # Calculate the total number of pixels\n",
    "    return bug_pixels / total_pixels  # devid\n",
    "\n",
    "# Calculate the ratio for all and creat a df\n",
    "bug_to_total_ratios = [bug_to_total_ratio(mask) for mask in masks]\n",
    "bug_to_total_ratios_df = pd.DataFrame(bug_to_total_ratios, columns=['ratio'])\n",
    "print (bug_to_total_ratios_df.head)\n",
    "\n",
    "# Print first 10 ratios\n",
    "#for i, ratio in enumerate(bug_to_total_ratios[:10]):\n",
    "#    print(f\"Bug to total pixel ratio for mask {i+1}: {ratio}\")\n",
    "\n",
    "# Merge the new feature \n",
    "data_features_df = pd.concat([data_features_df,bug_to_total_ratios_df], axis=1)\n",
    "#classif_df.to_csv('data_features.csv', index=False)\n",
    "#print(data_features_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   min_red  min_green  min_blue  max_red  max_green  max_blue    mean_red  \\\n",
      "0        0          0         0      208        208       208   54.286820   \n",
      "1        0          0         0      251        251       251   50.533765   \n",
      "2        0          0         0      255        255       255   86.118029   \n",
      "3        0          0         0      219        219       219   69.684210   \n",
      "4        0          0         0      255        255       255  101.673712   \n",
      "\n",
      "   mean_green   mean_blue  median_red  median_green  median_blue    std_red  \\\n",
      "0   54.286820   54.286820        37.0          37.0         37.0  44.962646   \n",
      "1   50.533765   50.533765        35.0          35.0         35.0  41.672498   \n",
      "2   86.118029   86.118029        82.0          82.0         82.0  60.634858   \n",
      "3   69.684210   69.684210        61.0          61.0         61.0  46.061015   \n",
      "4  101.673712  101.673712        99.0          99.0         99.0  64.366072   \n",
      "\n",
      "   std_green   std_blue  \n",
      "0  44.962646  44.962646  \n",
      "1  41.672498  41.672498  \n",
      "2  60.634858  60.634858  \n",
      "3  46.061015  46.061015  \n",
      "4  64.366072  64.366072  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"calculate the min, max, and mean values the median and standard deviation for RGB channels within the bug mask\"\"\"\n",
    "def color_stats(image, mask):\n",
    "    # Apply the mask to the image\n",
    "    masked_image = image[mask > 0]\n",
    "\n",
    "    if  masked_image.ndim == 1  or masked_image.shape[1] != 3: #not with a RGB tableau one dimo or 3 shape\n",
    "        # If masked_image is grey\n",
    "        min_val = masked_image.min()\n",
    "        max_val = masked_image.max()\n",
    "        mean_val = masked_image.mean()\n",
    "        median_val = np.median(masked_image)\n",
    "        std_val = np.std(masked_image)\n",
    "        stats = {\n",
    "            'min_red': min_val, 'min_green': min_val, 'min_blue': min_val,\n",
    "            'max_red': max_val, 'max_green': max_val, 'max_blue': max_val,\n",
    "            'mean_red': mean_val, 'mean_green': mean_val, 'mean_blue': mean_val,\n",
    "            'median_red': median_val, 'median_green': median_val, 'median_blue': median_val,\n",
    "            'std_red': std_val, 'std_green': std_val, 'std_blue': std_val,\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "    # for RGB\n",
    "        min_vals = masked_image.min(axis=0)\n",
    "        max_vals = masked_image.max(axis=0)\n",
    "        mean_vals = masked_image.mean(axis=0)\n",
    "        median_vals = np.median(masked_image, axis=0)\n",
    "        std_vals = np.std(masked_image, axis=0)\n",
    "    \n",
    "    # Create a dictionary to store the results\n",
    "        stats = {\n",
    "            'min_red': min_vals[0], 'min_green': min_vals[1], 'min_blue': min_vals[2],\n",
    "            'max_red': max_vals[0], 'max_green': max_vals[1], 'max_blue': max_vals[2],\n",
    "            'mean_red': mean_vals[0], 'mean_green': mean_vals[1], 'mean_blue': mean_vals[2],\n",
    "            'median_red': median_vals[0], 'median_green': median_vals[1], 'median_blue': median_vals[2],\n",
    "            'std_red': std_vals[0], 'std_green': std_vals[1], 'std_blue': std_vals[2],\n",
    "        }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "# Calculate the color statistics for all images and masks and create a df\n",
    "color_stats_list = [color_stats(img, mask) for img, mask in zip(images, masks)]\n",
    "color_stats_df = pd.DataFrame(color_stats_list)\n",
    "print(color_stats_df.head())\n",
    "\n",
    "# Print the first 10 color statistics\n",
    "#for i, stats in enumerate(color_stats_list[:10]):\n",
    "#    print(f\"Color stats for image {i+1}: {stats}\")\n",
    "\n",
    "# Merge the new features with the classification DataFrame\n",
    "data_features_df = pd.concat([data_features_df,color_stats_df], axis=1)\n",
    "#data_features_df.to_csv('data_features.csv', index=False)\n",
    "# print(data_features_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   contrast  homogeneity    energy  correlation\n",
      "0  1.478668     0.725038  0.052065     0.999783\n",
      "1  1.677912     0.724125  0.053770     0.999756\n",
      "2  2.528066     0.679071  0.043417     0.999685\n",
      "3  2.274407     0.638564  0.045116     0.999476\n",
      "4  2.466985     0.682676  0.043565     0.999690\n",
      "   SymmetryIndex  LongestOrthogonalRatio     ratio  min_red  min_green  \\\n",
      "0       0.804721                0.821019  0.022284        0          0   \n",
      "1       0.772273                0.675619  0.025659        0          0   \n",
      "2       0.593619                0.805196  0.066279        0          0   \n",
      "3       0.487819                0.709335  0.039562        0          0   \n",
      "4       0.666718                0.744057  0.027494        0          0   \n",
      "\n",
      "   min_blue  max_red  max_green  max_blue    mean_red  ...  median_red  \\\n",
      "0         0      208        208       208   54.286820  ...        37.0   \n",
      "1         0      251        251       251   50.533765  ...        35.0   \n",
      "2         0      255        255       255   86.118029  ...        82.0   \n",
      "3         0      219        219       219   69.684210  ...        61.0   \n",
      "4         0      255        255       255  101.673712  ...        99.0   \n",
      "\n",
      "   median_green  median_blue    std_red  std_green   std_blue  contrast  \\\n",
      "0          37.0         37.0  44.962646  44.962646  44.962646  1.478668   \n",
      "1          35.0         35.0  41.672498  41.672498  41.672498  1.677912   \n",
      "2          82.0         82.0  60.634858  60.634858  60.634858  2.528066   \n",
      "3          61.0         61.0  46.061015  46.061015  46.061015  2.274407   \n",
      "4          99.0         99.0  64.366072  64.366072  64.366072  2.466985   \n",
      "\n",
      "   homogeneity    energy  correlation  \n",
      "0     0.725038  0.052065     0.999783  \n",
      "1     0.724125  0.053770     0.999756  \n",
      "2     0.679071  0.043417     0.999685  \n",
      "3     0.638564  0.045116     0.999476  \n",
      "4     0.682676  0.043565     0.999690  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"calculate texture features using GLCM\"\"\"\n",
    "\n",
    "def texture_features(image, mask):\n",
    "\n",
    "    gray_image = rgb2gray(image)\n",
    "    glcm = graycomatrix((gray_image* 255).astype('uint8'), [1], [0, np.pi/2], symmetric=True, normed=True)\n",
    "    \n",
    "    # Extract texture features\n",
    "    contrast = graycoprops(glcm, 'contrast').mean()\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity').mean()\n",
    "    energy = graycoprops(glcm, 'energy').mean()\n",
    "    correlation = graycoprops(glcm, 'correlation').mean()\n",
    "\n",
    "    stats = {\n",
    "        'contrast': contrast,\n",
    "        'homogeneity': homogeneity,\n",
    "        'energy': energy,\n",
    "        'correlation': correlation\n",
    "    }  \n",
    "     \n",
    "    return stats\n",
    "\n",
    "# Calculate the texture features for all images and masks and create df\n",
    "texture_features_list = [texture_features(img, mask) for img, mask in zip(images, masks)]\n",
    "texture_features_df = pd.DataFrame(texture_features_list)\n",
    "print(texture_features_df.head())\n",
    "\n",
    "# Merge the new features with the classification DataFrame\n",
    "data_features_df = pd.concat([data_features_df,texture_features_df], axis=1)\n",
    "data_features_df.to_csv('data_features.csv', index=False)\n",
    "print(data_features_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_features_df = data_features_df\n",
    "new_data_features_df = new_data_features_df.drop(columns=['SymmetryIndex','LongestOrthogonalRatio','std_blue','std_green','std_red','correlation','contrast','min_red','min_green','min_blue','max_red','max_green','max_blue'])\n",
    "new_data_features_df.to_csv('data_features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
